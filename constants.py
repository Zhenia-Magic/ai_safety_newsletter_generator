# AI research labs, safety organizations, and key companies in the AI space
AI_ORGANIZATIONS = [
    "OpenAI",
    "Anthropic",
    "DeepMind",
    "Google AI",
    "Meta AI",
    "Microsoft AI",
    "xAI",
    "Mistral AI",
    "Cohere",
    "Stability AI",
    "Inflection AI",
    "AI21 Labs",
    "Hugging Face",
    "NVIDIA AI",
    "Amazon AI",
    "Apple AI",
    "IBM AI",
    "Baidu AI",
    "Alibaba AI",
    "Tencent AI",
    # Safety-focused orgs
    "Center for AI Safety",
    "MIRI",
    "Future of Life Institute",
    "Partnership on AI",
    "AI Now Institute",
    "Center for Human-Compatible AI",
    "Alignment Research Center",
    "Redwood Research",
    "EleutherAI",
    # Government & regulatory
    "NIST AI",
    "EU AI Act",
    "AI Safety Institute",
]

DEFAULT_ORGS_INPUT = ", ".join(AI_ORGANIZATIONS)

# Keywords for filtering AI safety and security related content
AI_SAFETY_TERMS = [
    # Core AI safety concepts
    "ai safety", "ai alignment", "ai risk", "existential risk", "x-risk",
    "agi", "artificial general intelligence", "superintelligence",
    "ai governance", "ai regulation", "ai policy", "ai ethics",
    # Security and threats
    "ai security", "ai threat", "ai danger", "ai harm", "ai misuse",
    "deepfake", "ai-generated", "synthetic media", "disinformation",
    "autonomous weapons", "lethal autonomous", "ai warfare",
    "cybersecurity ai", "ai cyberattack", "adversarial ai",
    # Alignment and control
    "alignment problem", "value alignment", "goal alignment",
    "ai control", "ai containment", "corrigibility", "interpretability",
    "explainable ai", "xai", "black box", "ai transparency",
    # Societal impact
    "ai unemployment", "job displacement", "automation risk",
    "ai bias", "algorithmic bias", "ai discrimination", "ai fairness",
    "ai surveillance", "mass surveillance", "privacy ai",
    # Technical safety
    "reward hacking", "specification gaming", "mesa-optimization",
    "distributional shift", "robustness", "ai failure",
    "hallucination", "confabulation", "ai accuracy",
    # Research and development
    "frontier ai", "foundation model", "large language model", "llm",
    "gpt", "claude", "gemini", "llama", "chatgpt",
    "ai capability", "ai breakthrough", "ai advancement",
    "machine learning", "deep learning", "neural network",
    "ai research", "ai development", "ai lab",
    # Governance and institutions
    "ai summit", "ai treaty", "ai moratorium", "ai pause",
    "responsible ai", "trustworthy ai", "beneficial ai",
    "ai audit", "ai assessment", "ai evaluation",
]

# Newsletter sections for categorization
NEWSLETTER_SECTIONS = [
    "AI Safety & Alignment",
    "Security & Threats", 
    "Governance & Regulation",
    "Industry Developments",
    "Research & Breakthroughs",
]
